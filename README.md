# Intership Project: Learn To Build A Real Time Gen AI Customer Service Bot

# Task 3: Multi-Modal Chatbot (Text and Image Analysis)

### Introduction
This project extends the functionality of a chatbot to handle both text and image content using Google Palm and Gemini AI. The chatbot can understand text-based queries, generate textual responses, and analyze and generate relevant descriptions from image inputs, combining textual and visual understanding for a seamless interaction.

### Background
Traditional chatbots handle only text inputs, generating responses based on natural language understanding. With advancements in AI, itâ€™s possible to extend these capabilities to multimodal models like Gemini AI, which can analyze both text and images. By integrating these features, the chatbot can provide more dynamic and versatile responses based on both visual and textual content.

### Learning Objectives
* Integrate Google Palm and Gemini AI for multimodal capabilities.
* Develop a system that can accept and analyze image inputs from users.
* Generate relevant and intelligent textual responses based on image content.
* Enhance the user experience by combining text and image-based interactions.

### Skills and Competencies
* Programming Languages: Python
* Streamlit for web interface development
* Google Generative AI (Gemini API) for multimodal capabilities
* PIL (Pillow) for image handling
* AI and Machine Learning: Understanding of multimodal models and API integration
* API Integration: Working with the Gemini AI API for text and image analysis



## Evidence
* Text Generation
![App Screenshot](https://github.com/VigneshvickyData/Data_Branching/blob/main/MMC-1.png?raw=true)

* Image Generation and Analysis
![App Screenshot](https://github.com/VigneshvickyData/Data_Branching/blob/main/MMC-2.png?raw=true)
![App Screenshot](https://github.com/VigneshvickyData/Data_Branching/blob/main/MMC-3.png?raw=true)
![App Screenshot](https://github.com/VigneshvickyData/Data_Branching/blob/main/MMC-4.png?raw=true)

### Conclusion
This project successfully extends a traditional text-based chatbot into a multi-modal system, capable of understanding and analyzing both text and image inputs. By leveraging Google Palm and Gemini AI, the chatbot is able to provide contextual responses, improving the user experience and demonstrating the power of modern AI models in multimodal communication. The project also highlights key challenges in handling image content and how integrating AI capabilities can overcome those challenges.